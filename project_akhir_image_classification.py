# -*- coding: utf-8 -*-
"""Project-Akhir-Image-Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1htKxPnPNIoTY0dfZzTqF8ZijK2IkT16-
"""

import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

import zipfile
from google.colab import drive

drive.mount('/content/drive/')
zip_ref = zipfile.ZipFile("/content/drive/My Drive/image-dataset/dataset-bunga.zip", 'r')
zip_ref.extractall("/tmp/dataset-bunga")
zip_ref.close()

os.listdir('/tmp/dataset-bunga/dataset-bunga')

base_dir = '/tmp/dataset-bunga/dataset-bunga/17FlowerOxfordDataset'

from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_generator = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    zoom_range = 0.2,
                    fill_mode = 'nearest',
                    validation_split = 0.2)

val_generator = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    zoom_range = 0.2,
                    fill_mode = 'nearest',
                    validation_split = 0.2)

train_generator = train_generator.flow_from_directory(
        base_dir,
        target_size=(150, 150),
        batch_size=4,
        class_mode='categorical',
        subset = 'training')

validation_generator = val_generator.flow_from_directory(
        base_dir,
        target_size=(150, 150),
        batch_size=4,
        class_mode='categorical',
        subset = 'validation')

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(15, activation='softmax')
])

int_lr = 1e-4

model.compile(loss='categorical_crossentropy',
              optimizer = tf.optimizers.Adam(learning_rate=int_lr),
              metrics=['accuracy'])

ACC_THRESHOLD = 0.80

# Stop training saat accuracy mencapai 90%

class myCallback(tf.keras.callbacks.Callback):
	def on_epoch_end(self, epoch, logs={}):
		if(logs.get('accuracy') > ACC_THRESHOLD and logs.get('val_accuracy') > ACC_THRESHOLD):
			print("\nReached %2.2f%% accuracy, so stopping training!!" %(ACC_THRESHOLD*100))
			self.model.stop_training = True

callback = myCallback()

history = model.fit(
    train_generator,
    epochs=30,
    validation_data=validation_generator,
    validation_steps=25,
    verbose=2,
    callbacks=[callback]
)

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

import pathlib

# Menyimpan model dalam format SavedModel
export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

# Convert SavedModel menjadi vegs.tflite
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('vegs.tflite')
tflite_model_file.write_bytes(tflite_model)

